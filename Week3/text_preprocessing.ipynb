{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __라이브러리 로드__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of comments\n",
    "NOC = 50\n",
    "#k = 0 #start idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1. 데이터 크롤링__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. 데이터 전처리__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __2.1 크롤링 데이터 로드__\n",
    "- 로드 후 일단 10개만 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194914</td>\n",
       "      <td>이 교수님 정말 재미있게 강의해주시네요... 자주 뵈었음 좋겠습니다.</td>\n",
       "      <td>김기범 교수님  쓸데없는 은유나 비유없이  요점만 명확히 설명 해 주셔서  이해도 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     view                                       0  \\\n",
       "0  194914  이 교수님 정말 재미있게 강의해주시네요... 자주 뵈었음 좋겠습니다.   \n",
       "\n",
       "                                                   1  \n",
       "0  김기범 교수님  쓸데없는 은유나 비유없이  요점만 명확히 설명 해 주셔서  이해도 ...  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"youtube_replies.xlsx\")\n",
    "#cols = list(df.keys())[1:]\n",
    "df_trans = df.T[1:].reset_index()\n",
    "df_trans.rename(columns={'index':'view'}, inplace=True)\n",
    "df_trans.iloc[:1,:3] #example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame([])\n",
    "new_df[\"Views\"] = df_trans[\"view\"]\n",
    "new_df[\"comments\"] = df_trans.iloc[:,1] #df_trans.iloc[:,1:11] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Views</th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194914</td>\n",
       "      <td>이 교수님 정말 재미있게 강의해주시네요... 자주 뵈었음 좋겠습니다.\\n김기범 교수...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319933</td>\n",
       "      <td>OCN에 켠김에 왕까지에서 허준씨를 처음 봤을때는 이렇게 될 줄은 상상도 못 했습니...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98384</td>\n",
       "      <td>교수님 강의를 이렇게 쉽게 들을 수 있다니 행운이고 감사합니다.\\n학창시절땐 과학이...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>402196</td>\n",
       "      <td>영화 &lt;크리에이터&gt; 예매권 이벤트  이 영상에 영화에 대한 기대평 댓글을\\n남겨주신...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150218</td>\n",
       "      <td>우와 영상 재밌게봤어요! 넘넘 차분하게 전달력 있게 말씀해주시네요.. 하도 슈뢰딩거...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>287723</td>\n",
       "      <td>다양한 천문학 이야기 전할 수 있는 좋은 기회 주신 BODA 분들께 감사드립니다! ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2298575</td>\n",
       "      <td>곧 안전하고 값싼 우주 여행이 실현되길 바랍니다  우주 여행 관련 이야기할 수 있는...</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>362675</td>\n",
       "      <td>오늘도 초대해 주셔서 감사합니다!!!! 자주 놀러와서 축구 이야기 해볼게요!!영상 ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>353262</td>\n",
       "      <td>여자를 위해, 여자를 가장 잘 아는 산부인과의사언니 김지연 원장이 개발한 우먼스37...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>744042</td>\n",
       "      <td>스스로 타는 천체, 스타 개그는 제가 만든 거 아닙니다. 저도ㅠ배운거에요.. \\n어...</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Views                                           comments  label\n",
       "0     194914  이 교수님 정말 재미있게 강의해주시네요... 자주 뵈었음 좋겠습니다.\\n김기범 교수...   Good\n",
       "1     319933  OCN에 켠김에 왕까지에서 허준씨를 처음 봤을때는 이렇게 될 줄은 상상도 못 했습니...   Good\n",
       "3      98384  교수님 강의를 이렇게 쉽게 들을 수 있다니 행운이고 감사합니다.\\n학창시절땐 과학이...   Good\n",
       "4     402196  영화 <크리에이터> 예매권 이벤트  이 영상에 영화에 대한 기대평 댓글을\\n남겨주신...   Good\n",
       "5     150218  우와 영상 재밌게봤어요! 넘넘 차분하게 전달력 있게 말씀해주시네요.. 하도 슈뢰딩거...   Good\n",
       "..       ...                                                ...    ...\n",
       "195   287723  다양한 천문학 이야기 전할 수 있는 좋은 기회 주신 BODA 분들께 감사드립니다! ...   Good\n",
       "196  2298575  곧 안전하고 값싼 우주 여행이 실현되길 바랍니다  우주 여행 관련 이야기할 수 있는...  Great\n",
       "197   362675  오늘도 초대해 주셔서 감사합니다!!!! 자주 놀러와서 축구 이야기 해볼게요!!영상 ...   Good\n",
       "198   353262  여자를 위해, 여자를 가장 잘 아는 산부인과의사언니 김지연 원장이 개발한 우먼스37...   Good\n",
       "199   744042  스스로 타는 천체, 스타 개그는 제가 만든 거 아닙니다. 저도ㅠ배운거에요.. \\n어...  Great\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame([])\n",
    "new_df[\"Views\"] = df_trans[\"view\"]\n",
    "new_df[\"comments\"] = df_trans.iloc[:,1] #df_trans.iloc[:,1:11] \n",
    "for i in range(2,NOC+1): \n",
    "    new_df[\"comments\"] += \"\\n\" + df_trans.iloc[:,i]\n",
    "#60만회 초과인지 기준으로 \n",
    "new_df[\"label\"] = new_df[\"Views\"].apply(lambda x: 'Great' if int(x)>10e4*6 else 'Good')\n",
    "#new_df.fillna(\"\\n\", inplace=True)\n",
    "new_df = new_df.dropna() \n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __2.2 데이터 전처리__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Views</th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194914</td>\n",
       "      <td>이 교수님 정말 재미있게 강의해주시네요  자주 뵈었음 좋겠습니다  김기범 교수님  ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319933</td>\n",
       "      <td>OCN에 켠김에 왕까지에서 허준씨를 처음 봤을때는 이렇게 될 줄은 상상도 못 했습니...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98384</td>\n",
       "      <td>교수님 강의를 이렇게 쉽게 들을 수 있다니 행운이고 감사합니다  학창시절땐 과학이나...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>402196</td>\n",
       "      <td>영화  크리에이터  예매권 이벤트  이 영상에 영화에 대한 기대평 댓글을 남겨주신 ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150218</td>\n",
       "      <td>우와 영상 재밌게봤어요  넘넘 차분하게 전달력 있게 말씀해주시네요  하도 슈뢰딩거고...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>287723</td>\n",
       "      <td>다양한 천문학 이야기 전할 수 있는 좋은 기회 주신 BODA 분들께 감사드립니다  ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2298575</td>\n",
       "      <td>곧 안전하고 값싼 우주 여행이 실현되길 바랍니다  우주 여행 관련 이야기할 수 있는...</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>362675</td>\n",
       "      <td>오늘도 초대해 주셔서 감사합니다  자주 놀러와서 축구 이야기 해볼게요 영상 재미있게...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>353262</td>\n",
       "      <td>여자를 위해  여자를 가장 잘 아는 산부인과의사언니 김지연 원장이 개발한 우먼스37...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>744042</td>\n",
       "      <td>스스로 타는 천체  스타 개그는 제가 만든 거 아닙니다  저도ㅠ배운거에요   어려울...</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Views                                           comments  label\n",
       "0     194914  이 교수님 정말 재미있게 강의해주시네요  자주 뵈었음 좋겠습니다  김기범 교수님  ...   Good\n",
       "1     319933  OCN에 켠김에 왕까지에서 허준씨를 처음 봤을때는 이렇게 될 줄은 상상도 못 했습니...   Good\n",
       "3      98384  교수님 강의를 이렇게 쉽게 들을 수 있다니 행운이고 감사합니다  학창시절땐 과학이나...   Good\n",
       "4     402196  영화  크리에이터  예매권 이벤트  이 영상에 영화에 대한 기대평 댓글을 남겨주신 ...   Good\n",
       "5     150218  우와 영상 재밌게봤어요  넘넘 차분하게 전달력 있게 말씀해주시네요  하도 슈뢰딩거고...   Good\n",
       "..       ...                                                ...    ...\n",
       "195   287723  다양한 천문학 이야기 전할 수 있는 좋은 기회 주신 BODA 분들께 감사드립니다  ...   Good\n",
       "196  2298575  곧 안전하고 값싼 우주 여행이 실현되길 바랍니다  우주 여행 관련 이야기할 수 있는...  Great\n",
       "197   362675  오늘도 초대해 주셔서 감사합니다  자주 놀러와서 축구 이야기 해볼게요 영상 재미있게...   Good\n",
       "198   353262  여자를 위해  여자를 가장 잘 아는 산부인과의사언니 김지연 원장이 개발한 우먼스37...   Good\n",
       "199   744042  스스로 타는 천체  스타 개그는 제가 만든 거 아닙니다  저도ㅠ배운거에요   어려울...  Great\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#punctuation 제거, 특수문자 제거, lowercasing\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9 a-z A-Z]+', ' ', str(text))\n",
    "    text.lower()\n",
    "    return text\n",
    "\n",
    "new_df.comments = new_df.comments.apply(remove_white_space)\n",
    "new_df.comments = new_df.comments.apply(remove_special_char)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __2.3 토크나이징 및 변수 생성__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','ㅋㅋ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:34<00:00,  5.73it/s]\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(new_df['comments']):\n",
    "    tokenized_sentence = okt.morphs(sentence, norm=True, stem=True)  # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[교수, 님, 정말, 재미있다, 강의, 해주다, 자주, 뵈다, 좋다, 김기범, 교수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[OCN, 켜다, 김, 왕, 까지에, 서다, 허준, 씨, 처음, 보다, 때, 이렇게...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[교수, 님, 강의, 이렇게, 쉬다, 들다, 수, 있다, 행운, 이고, 감사하다, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[영화, 크리에이터, 예매, 권, 이벤트, 영상, 영화, 대한, 기, 대, 평, 댓...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[우와, 영상, 재밌다, 보다, 넘다, 넘다, 차분하다, 전달, 력, 있다, 말씀,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[다양하다, 천문학, 이야기, 전, 수, 있다, 좋다, 기회, 주신, BODA, 분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[곧, 안전하다, 값싸다, 우주, 여행, 실현, 되다, 바라다, 우주, 여행, 관련...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[오늘, 초대, 주다, 감사하다, 자주, 놀러와, 서, 축구, 이야기, 해보다, 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[여자, 위해, 여자, 가장, 자다, 알다, 산부인과, 의사, 언니, 김지연, 원장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[스스로, 타다, 천체, 스타, 개그, 제, 만들다, 거, 아니다, 저, ㅠ, 배우...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           token_final\n",
       "0    [교수, 님, 정말, 재미있다, 강의, 해주다, 자주, 뵈다, 좋다, 김기범, 교수...\n",
       "1    [OCN, 켜다, 김, 왕, 까지에, 서다, 허준, 씨, 처음, 보다, 때, 이렇게...\n",
       "2    [교수, 님, 강의, 이렇게, 쉬다, 들다, 수, 있다, 행운, 이고, 감사하다, ...\n",
       "3    [영화, 크리에이터, 예매, 권, 이벤트, 영상, 영화, 대한, 기, 대, 평, 댓...\n",
       "4    [우와, 영상, 재밌다, 보다, 넘다, 넘다, 차분하다, 전달, 력, 있다, 말씀,...\n",
       "..                                                 ...\n",
       "193  [다양하다, 천문학, 이야기, 전, 수, 있다, 좋다, 기회, 주신, BODA, 분...\n",
       "194  [곧, 안전하다, 값싸다, 우주, 여행, 실현, 되다, 바라다, 우주, 여행, 관련...\n",
       "195  [오늘, 초대, 주다, 감사하다, 자주, 놀러와, 서, 축구, 이야기, 해보다, 영...\n",
       "196  [여자, 위해, 여자, 가장, 자다, 알다, 산부인과, 의사, 언니, 김지연, 원장...\n",
       "197  [스스로, 타다, 천체, 스타, 개그, 제, 만들다, 거, 아니다, 저, ㅠ, 배우...\n",
       "\n",
       "[198 rows x 1 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df = pd.DataFrame([])\n",
    "tokenized_df[\"token_final\"] = tokenized_data\n",
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Good\n",
       "1       Good\n",
       "3       Good\n",
       "4       Good\n",
       "5       Good\n",
       "       ...  \n",
       "195     Good\n",
       "196    Great\n",
       "197     Good\n",
       "198     Good\n",
       "199    Great\n",
       "Name: label, Length: 198, dtype: object"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[교수, 님, 정말, 재미있다, 강의, 해주다, 자주, 뵈다, 좋다, 김기범, 교수...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[OCN, 켜다, 김, 왕, 까지에, 서다, 허준, 씨, 처음, 보다, 때, 이렇게...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[교수, 님, 강의, 이렇게, 쉬다, 들다, 수, 있다, 행운, 이고, 감사하다, ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[영화, 크리에이터, 예매, 권, 이벤트, 영상, 영화, 대한, 기, 대, 평, 댓...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[우와, 영상, 재밌다, 보다, 넘다, 넘다, 차분하다, 전달, 력, 있다, 말씀,...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         token_final label\n",
       "0  [교수, 님, 정말, 재미있다, 강의, 해주다, 자주, 뵈다, 좋다, 김기범, 교수...  Good\n",
       "1  [OCN, 켜다, 김, 왕, 까지에, 서다, 허준, 씨, 처음, 보다, 때, 이렇게...  Good\n",
       "2  [교수, 님, 강의, 이렇게, 쉬다, 들다, 수, 있다, 행운, 이고, 감사하다, ...  Good\n",
       "3  [영화, 크리에이터, 예매, 권, 이벤트, 영상, 영화, 대한, 기, 대, 평, 댓...  Good\n",
       "4  [우와, 영상, 재밌다, 보다, 넘다, 넘다, 차분하다, 전달, 력, 있다, 말씀,...  Good"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df = pd.DataFrame([])\n",
    "tokenized_df[\"token_final\"] = tokenized_data\n",
    "tokenized_df[\"label\"] = new_df.label\n",
    "tokenized_df[\"label\"] = tokenized_df[\"label\"].fillna('Good') \n",
    "#tokenized_df.dropna(inplace=True)\n",
    "tokenized_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============ 기존 코드 (비교용) ============\n",
    "#df = pd.DataFrame([])\n",
    "#df[\"token_noun\"] = new_df.comments.apply(okt.nouns)\n",
    "#df[\"token_morphs\"] = new_df.comments.apply(okt.morphs)\n",
    "#df[\"label\"] = new_df.label\n",
    "# ============ 저장 ================\n",
    "#df.to_csv(\"origin_noun.csv\", index=False, encoding='utf-8-sig')\n",
    "#df.to_csv(\"origin_morphs.csv\", index=False, encoding='utf-8-sig')\n",
    "tokenized_df.to_csv(\"tokenized_df_plus.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __2.4 단어 임베딩__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=18138, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "embedding_model = Word2Vec(tokenized_df['token_final'], \n",
    "                           sg = 2, # skip-gram\n",
    "                           vector_size = 100, \n",
    "                           window = 2, \n",
    "                           min_count = 1, \n",
    "                           workers = 8\n",
    "                           )\n",
    "\n",
    "print(embedding_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('방향', 0.9742190837860107), ('군대', 0.9709122180938721), ('과거', 0.9689631462097168), ('입장', 0.9677556753158569), ('생물', 0.9669126868247986), ('감정', 0.9665217399597168), ('결과', 0.9659112095832825), ('혹시', 0.9650603532791138), ('실험', 0.9631057381629944), ('경험', 0.9629468321800232)]\n"
     ]
    }
   ],
   "source": [
    "embedding_model.wv.save_word2vec_format('week3pj_tokens_eng_w2v')\n",
    "loaded_model = KeyedVectors.load_word2vec_format('week3pj_tokens_eng_w2v') # 모델 로드\n",
    "\n",
    "model_result = loaded_model.most_similar(\"AI\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3. 모델 학습__\n",
    "- 일단 테스트 모델은 임시로 Classification 문제로 정의함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.0 split data - train/val__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['교수', '님', '정말', '재미있다', '강의', '해주다', '자주', '...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['켜다', '김', '왕', '까지에', '서다', '허준', '씨', '처음',...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['교수', '님', '강의', '이렇게', '쉬다', '들다', '수', '있다'...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['영화', '크리에이터', '예매', '권', '이벤트', '영상', '영화', ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['우와', '영상', '재밌다', '보다', '넘다', '넘다', '차분하다', ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>['다양하다', '천문학', '이야기', '전', '수', '있다', '좋다', '...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>['곧', '안전하다', '값싸다', '우주', '여행', '실현', '되다', '...</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>['오늘', '초대', '주다', '감사하다', '자주', '놀러와', '서', '...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>['여자', '위해', '여자', '가장', '자다', '알다', '산부인과', '...</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>['스스로', '타다', '천체', '스타', '개그', '제', '만들다', '거...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           token_final  label\n",
       "0    ['교수', '님', '정말', '재미있다', '강의', '해주다', '자주', '...   Good\n",
       "1    ['켜다', '김', '왕', '까지에', '서다', '허준', '씨', '처음',...   Good\n",
       "2    ['교수', '님', '강의', '이렇게', '쉬다', '들다', '수', '있다'...   Good\n",
       "3    ['영화', '크리에이터', '예매', '권', '이벤트', '영상', '영화', ...   Good\n",
       "4    ['우와', '영상', '재밌다', '보다', '넘다', '넘다', '차분하다', ...   Good\n",
       "..                                                 ...    ...\n",
       "193  ['다양하다', '천문학', '이야기', '전', '수', '있다', '좋다', '...   Good\n",
       "194  ['곧', '안전하다', '값싸다', '우주', '여행', '실현', '되다', '...  Great\n",
       "195  ['오늘', '초대', '주다', '감사하다', '자주', '놀러와', '서', '...   Good\n",
       "196  ['여자', '위해', '여자', '가장', '자다', '알다', '산부인과', '...  Great\n",
       "197  ['스스로', '타다', '천체', '스타', '개그', '제', '만들다', '거...   Good\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tokenized_df.csv\")\n",
    "#df = df.drop(labels=\"Unnamed: 0\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = RandomState()\n",
    "\n",
    "tr = df.sample(frac=0.8, random_state=rng)\n",
    "val = df.loc[~df.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.1 실험 설계__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy.data import Field #from torchtext.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
    "    text = text.split(', ')\n",
    "    return text\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['이번', '역다', '우리', '은하', '철도', '종착역', '인', '안드로메다', '안드로메다', '이다', '우주먼지', '님', '차다', '설명', '을', '알차다', '많다', '우주', '유튜버들', '을', '보고', '있다', '한데', '어렵다', '내용', '을', '편하다', '말씀', '능력', '월등', '해', '요', '우주먼지', '지웅', '배', '님', '을', '알', '게', '되다', '전', '까지는', '정도', '우주', '지식', '을', '갖다', '있다', '사람', '해외', '에만', '존재', '알다', '정말', '너무', '너무', '신기하다', '알다', '아', '는걸', '설명', '정말', '다른', '차원', '이란', '걸', '또', '느끼다', '설명', '을', '전부', '다', '알다', '내용', '인데', '흥미롭다', '보다', '정말', '쉬다', '이해', '좋다', '설명', '해주다', '감사하다', '오다', '도플러', '효과', '대해', '이렇게', '쉬다', '설명', '해주다', '감동', '이네', '요', '이렇게', '어렵다', '이야기', '이렇다', '쉬다', '설명', '얼마나', '연구', '하고', '공부', '그', '덕', '을', '제', '보다', '넘다', '감사하다', '정말로', '쉬다', '설명', '을', '명확하다', '너무나', '자다', '설명', '주다', '사실', '어떻다', '사실', '을', '알', '아', '들다', '없다', '어렵다', '말로', '설명', '사람', '진정하다', '전문가', '아니다', '왜냐면', '본인', '정확하다', '이해', '못', '때문', '액면', '그대로', '설명', '보다', '어렵다', '설명', '겁니다', '대한민국', '천문학', '이런', '분', '의하다', '밝다', '생각', '안드로메다', '존재', '외계', '문', '명도', '멀다', '미래', '충돌', '우리', '은하', '의식', '하고', '있다', '것', '같다', '기분', '묘', '또한', '우리', '은하', '앞서다', '외계', '문명', '안드로메다', '존재', '인식', '동시', '은하', '중심', '궁수자리', '블랙홀', '을', '필연', '적', '연구', '않다', '그렇다', '수학', '물리학', '천문학', '등', '과학', '우주', '공통', '언어', '인', '세다', '즉', '우주', '어디', '에서나', '생판', '모르다', '외계인', '을', '만나다', '과학', '우주', '관', '많다', '대화', '수', '있다', '공감', '대', '형성', '수', '있다', '겁니다', 'ㅎㅎ', '그', '어렵다', '우주', '너무도', '쉬다', '재밌다', '설명', '해주다', '우주', '이야기', '많이', '올려주다', '우주', '대해', '진화', '대해', '자다', '설명', '주다', '감사', '드리다', '지웅', '배', '님', '항상', '재밌다', '영상', '보고', '있다', '상당하다', '유익하다', '저렇게', '진지하다', '조곤조곤하다', '목소리', '로', '커플링', '충돌', '은하', '일련번호', '새기다', '보다', '어떻다', 'ㅋㅋㅋ', '우주먼지', '님', '멘트', '빵터지다', 'ㅋㅋㅋ', '내용', '충실하다', '알아듣다', '쉬다', '설명', '고맙다', '아니다', '도플러', '효과', '절대', '안', '까먹다', '소', '음원', '청음', '거리', '따르다', '주파수', '설명', '을', '이렇게', '직관', '적', 'ㄷㄷ', '우리은하', '안드로메다', '이야기', '파장', '관련', '이야기', '하트', '갤럭시', '이야기', '커플링', '의미', '부여', '까지', '어느', '하나', '빠지다', '않다', '설명', '최고', '네', '요', '진짜', '똑똑하다', '말', 'ㄷㄷ', '알다', '쉬다', '자다', '설명', '재밌다', '깔끔하다', '정리', '되다', '우주', '이야기', '자다', '보다', '헤어스타일', '나선형', '은하', '스타일', '시', '네', '요', 'ㅎㅎ', '역시', '낭만', '천문학자', '먼지', '형', '13', '05', '부분', '보다', '이분', '정말', '찌다', '생각', '멋지다', '학자', '되다', '응원', '수없이', '보내다', '개념', '을', '돌려주다', '위해', '달려오다', '안드로메다', '정말', '많다', '이해', '판단', '을', '해주다', '설명', '듣다', '갑', 'ㄴㅣ', '다', '감사하다', '충돌', '아니다', '서로', '섞이다', '것', '이고', '지금', '우리', '살', '고', '있다', '우주', '환경', '에는', '전혀', '변화', '없다', '것', '같다', '워낙', '규모', '크다', '은하', '이기', '때문', '3', '40억년', '쯤', '뒤', '면', '안드로메다은하', '굉장하다', '크게', '보이다', '밤하늘', '떠오르다', '장관', '이지', '않다', '그렇다', '점점', '다가오다', '충돌', '직전', '되다', '밤하늘', '을', '거대하다', '수', '놓다', '그', '모습', '을', '살다', '보다', '설명', '진짜', '해주다', '네', '용', '우주', '대해', '막연하다', '생각', '오다', '지', '융배', '님', '덕', '신비롭다', '지구', '우주', '새롭다', '생각', '되다', '거', '같다', '역시', '우주', '이야기', '언제', '들다', '재밌다', '거', '같다', '1시간', '110', '키', '로', '아니다', '1초', '110', '키', '로라', '니', '상상', '안', '간다', '십', '소름', '인데', '그', '속', '도로', '가장', '가깝다', '은하', '인데', '어마어마하다', '오래', '걸리다', '소름', '영상', '을', '다', '보다', '안드로메다', '92', '400', '정도', '가까이', '다가오다', '느껴지다', '오', '호', '라', '우리', '을', '떠나가다', '개념', '1초', '110', '씩', '되다', '돌다', '오다', '저', '궁금하다', '게', '있다', '서로', '다른', '두', '은하', '사이', '거리', '빛', '속', '도로', '엄청', '멀다', '다른', '은하', '어디', '있다', '어떻다', '알다', '중력', '작용', '하', '는걸', '끄다', '다시', '말', '몇', '백만', '광년', '만큼', '떨어지다', '은하', '서로', '존재', '알다', '속도', '빛', '속도', '보다', '빠르다', '건가', '요', '두', '은하', '몇', '백만', '광년', '길이', '팽팽', '줄', '로', '연결하다', '치다', '쪽', '에서', '당기다', '힘', '다른', '쪽', '전달', '되다', '시간', '걸리다', '현자', '타임', '흥미', '있다', '보다', '구', '독자', '이다', '막히다', '없이', '술술', '설명', '너무', '좋다', '우리은하', '안드로메다은하', '충돌', '모습', '을', '헤어스타일', '로', '표현', 'ㄷㄷ', '이분', '제', '보다', '우주과학', '말', '분', '중', '에서', '제일', '듣기', '좋다', '먼지', '박사', '님', '더', '흥미롭다', '우주', '사건', '을', '부탁', '선생님', '영상', '을', '보다', '궁금하다', '것', '생기다', '이렇게', '질문', '을', '남기다', '우주', '있다', '천체', '왜', '회전', '을', '하나요', '회전', '어디', '에서부터', '시작', '되다', '것', '인가요', '우주', '등등', '관심', '있다', '검색', '해보다', '이분', '이해', '쉬다', '재밌다', '설명', '잘해주다', '이야', '시청', '내내', '지루하다', '않다', '재미', '가미', '되다', '천체', '이야기', '감사하다', '재밌다', '구독', '보다', '40억년', '이나', '걸리다', '충돌', '걱정', '필요', '없다', '그래서', '다가오다', '것', '을', '알', '고', '속도', '알다', '보다', '감사하다', '은하', '충돌', '후', '태양', '위치', '어떻다', '되다', '아직', '예측', '안되다', '태양', '다른', '별', '충돌', '않다', '태양', '현재', '상태', '에서', '변하다', '않다', '가정', '지구', '운명', '어찌', '되다', '모르다', '일단', '은하', '중심부', '가깝다', '지면', '우주', '천체', '밀도', '높아지다', '그', '수많다', '천체', '발생', '시키다', '우주', '방사선', '을', '지구', '생명체', '버티다', '보장', '안되다', '말', '죠', '먼지', '형', '볼', '수록', '사랑', '꾼', '이여', '이제', '개념', '을', '안드로메다', '로', '보내다', '사람', '개념', '돌아오다', '것', '인가', '진짜', '천문학', '영상', '보다', '영생', '이유', '자꾸', '생기다', '근데', '없다', '너무', '슬프다', 'ㅠㅠ', '아날로그', '로', '구현', '도플러', '이펙트', '최고다', 'ㅋㅋㅋ', '강하다', '중력', '먼지', '님', '머리', '우상', '단', '방향', '인가', '보다', '궁금하다', '있다', '은하', '중심부', '에는', '어마어마하다', '심장', '같다', '블랙홀', '있다', '두', '거대하다', '은하', '충돌', '섞이다', '때', '혹시', '그', '중심부', '끼리', '우연히', '라도', '만나다', '진짜', '말', '안되다', '크기', '블랙홀', '되다', '같다', '그땐', '어떻다', '되다', '초속', '110', '면', '도대체', '얼마나', '빠르다', '속도', '인지', '상상', '안', '돼다', '혹시', '우리', '은하', '안드로메다', '은하', '점점', '가까워지다', '지다', '속도', '가속', '되다', '않다', '같다', '중력', '일', '때', '거리', '가까워지다', '힘', '을', '더', '많이', '받다', '되다', '않다', '아', '그렇다', '나선', '아직', '반죽', '안되다', '은하', '고', '타원은하', '반죽', '최소', '1', '번은', '되다', '은하', '일', '가능성', '높다'] Great\n",
      "Validation: ['교수', '님', '정말', '재미있다', '강의', '해주다', '자주', '뵈다', '좋다', '김기범', '교수', '님', '쓸데없다', '은유', '나', '비유', '없이', '요점', '만', '명확하다', '설명', '해', '주다', '이해도', '쏙쏙', '되다', '지루하다', '않다', '재밌다', 'ㅉㅉㅉ', '교수', '님', '목소리', '엄청', '좋다', '차분하다', '설명', '을', '엄청', '쉬다', '자다', '같다', '과학', '을', '보다', '함께', '자다', '어울리다', 'ㅎㅎ', '그렇다', '번', '출연', '해주다', '좋다', '더', '더욱', '울릉도', '일', '본', '쪽', '가깝다', '지진', '영향', '울릉도', '아래', '있다', '마그마', '방이', '더', '자극받다', '같다', '전문가', '분', '울릉도', '위험', '1', '순위', '로', '보다', '정부', '차원', '에서도', '울릉도', '주민', '약', '9천', '명', '관광객', '을', '비상', '시', '내륙', '빨리', '대피', '시키다', '있다', '가이드라인', '메뉴얼', '을', '만들다', '않다', '생각', '드네', '요', '공항', '짓다', '어쩌면', '돈벌이', '이다', '울릉도', '화', '산이', '폭팔', '진짜', '큰일', '이군', '요', '울릉도', '에서', '폭발', '도망가다', '때', '없다', '그냥', '사람', '전부', '폼페이', '처럼', '녹음', 'ㄷㄷ', '궁금하다', '내용', '재미있다', '보고', '있다', '질문', '있다', '과거', '마그마', '분출', '철원', '평야', '제주도', '지하', '에는', '마그마', '방이', '사라지다', '있다', '어느', '정도', '크기', '로', '재', '분화', '가능성', '있다', '전달', '력', '뛰어나다', '좋다', '영상', '잘봣습니', '다', '멋지다', '꼭', '계속', '활동', '우릴', '지키다', '화산', '대해', '서', '아주', '관심', '갖다', '들다', '더', '크다', '관심', '생기다', '자주', '나오다', '줄다', '역시', '보다', '수준', '최고', '이다', '감사하다', '미래', '울릉도', '화산', '분화', '생각', '못', '재밌다', '들다', '마그마', '분화', '백두산', '후지산', '만', '놓다', '보다', '울릉도', '정말', '생각', '지도', '못', '일', '탈', '계', '팬', '트리', '처자', '여기', '서', 'ㅎ', '몰래', '1', '나잇', '다니다', '긴급', '울릉도', '독도', '사이', '해저화산', '분화', '알다', '울릉도', '더', '분화', '위험', '높다', '일', '탈', '계', '팬', '트리', '처자', '여기', '서', 'ㅎ', '몰래', '1', '나잇', '다니다', '긴급', '마그마', '천천히', '흘러나오다', '독도', '랑', '연결', '되다', '전투기', '뜰', '수', '있다', '미사일', '도배', '수', '있다', '새', '땅', '생깅션', '좋다', '자주', '나오다', '좋다', '말', '톤', '좋다', '화산', '용어', '중', '휴화산', '사화산', '이란', '단어', '더', '이상', '안', '쓰다', '있다', '왜냐하면', '사화산', '인', '줄', '알다', '화산', '활동', '을', '사례', '있다', '일', '탈', '계', '팬', '트리', '처자', '여기', '서', 'ㅎ', '몰래', '1', '나잇', '다니다', '긴급', '기범이', '형', '화이팅', '철원', '위', '추가령', '고대', '화산', '있다', '울릉도', '관광', '영업', '행태', '보다', '서다', '태초', '모습', '리셋', '되다', '것', '나쁘다', '않다', '일', '탈', '계', '팬', '트리', '처자', '여기', '서', 'ㅎ', '몰래', '1', '나잇', '다니다', '긴급', '울릉도', '분화', '가능성', '있다', '아예', '모르다', '경북', '청송', '주왕산', '일반', '그냥', '산', '되다', '게', '천만다행', '이지', '주왕산', '일대', '원래', '화산', '지대', '이다', '울릉도', '뒤통수', '니', '킥', '맞다', '것', '같다', '착각', '들다', '정도', '로', '충격', '적다', '사투리', '한번', '씩', '나오니', '친근하다', '나', '사람', '목소리', '톤', '분위기', '너무', '좋다', '요즘', '이렇다', '텐션', '정도', '딱', '좋다', '것', '같다', '교수', '님', '오리산', '얘기', '해주다', '편안하다', '듣기', '좋다', '목소리', '시', '다', '지질학자', '로', '전향', '무릎', '폼', '미치다', '한반도', '지형', '활화산', '을', '말', '백두산', '한라산', '울릉도', '오리산', '4', '개', '있다', '강', '형', '욱', '님', '언제', '화산', '공부', '까지', '대단하다', '감사하다', '흥미', '롭고', '재밌다', '감사하다', '영상', '에서', '거품', '나', '장소', '어디', '인가요', '다른', '영상', '을', '보다', '수온', '20', '조금', '넘다', '것', '을', '보다', '과학자', '기술자', '전문가', '말', '을', '무시', '안되다', '그', '만큼', '경험', '지식', '있다', '사람', '이라', '100', '수용', '어렵다', '미리', '준비', '그게', '1천년', '후에', '일어나다', '일이', '라', '해도', '설마', '몇', '백년', '후', '에는', '다', '들다', '지', '구', '밖', '정거장', '임시', '머무르다', '다시', '잠잠하다', '지구', '로', '돌아오다', '상황', '있다', '있다', '나리분지', '살다', '분들', '안전', '을', '위해', '서', '주시', '켜다', '아니다', '백두산', '규모', '두다', '뿐', '이다', '조용조', '용', '물', '흐르다', '말', '제', '스탈', '용', '오늘', '한복', '을', '입다', '계시다', '화산', '김구', '선생님', '울릉도', '폭발', '섬', '생기', '면', '개이득', '울릉', '도민', '집값', '떨어지다', '싫어하다', '영상', '1', '위', 'ㅋㅋㅋ', '오다', '진짜', '몰입', '보다', 'ㅎㅎ', '교수', '님', '진짜', '뭔가', '생기다', '고귀하다', '보임', 'ㅋㅋㅋ'] Good\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy.data import TabularDataset #from torchtext.data import TabularDataset \n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = './',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text,  train[0].label)\n",
    "print(\"Validation:\", validation[0].text, validation[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수와 차원 : torch.Size([15495, 100]) \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.legacy.data import BucketIterator #from torchtext.data import BucketIterator \n",
    "\n",
    "vectors = Vectors(name=\"week3pj_tokens_w2v\")\n",
    "\n",
    "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train, validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "\n",
    "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.2 TextCNN 모델링__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class TextCNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
    "    \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()                \n",
    "        self.dropout = nn.Dropout(0.4)         \n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
    "        \n",
    "    def forward(self, x):  \n",
    "      \n",
    "        emb_x = self.embed(x)           \n",
    "        emb_x = emb_x.unsqueeze(1)  \n",
    "\n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
    "\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1) \n",
    "        fc_x = fc_x.squeeze(-1)       \n",
    "        fc_x = self.dropout(fc_x)         \n",
    "\n",
    "        logit = self.fc(fc_x)     \n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.3 모델 train/eavluate 함수 정의__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()                               \n",
    "    corrects, train_loss = 0.0,0        \n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label      \n",
    "        text = torch.transpose(text, 0, 1)          \n",
    "        target.data.sub_(1)                                 \n",
    "        text, target = text.to(device), target.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()                           \n",
    "        logit = model(text)                         \n",
    "    \n",
    "        loss = F.cross_entropy(logit, target)   \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "        result = torch.max(logit,1)[1] \n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
    "\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    corrects, test_loss = 0.0, 0\n",
    "\n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        \n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "        #print(target,logit)\n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "\n",
    "    test_loss /= len(itr.dataset) \n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.4 모델 학습 및 성능 확인__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(15495, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 10, kernel_size=(1, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 10, kernel_size=(1, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 10, kernel_size=(1, 100), stride=(1, 1))\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "Train Epoch: 1 \t Loss: 0.08567318244825435 \t Accuracy: 60.75949478149414%\n",
      "Valid Epoch: 1 \t Loss: 0.07931894212961196 \t Accuracy: 70.0%\n",
      "model saves at 70.0 accuracy\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 2 \t Loss: 0.08351742164998115 \t Accuracy: 63.2911376953125%\n",
      "Valid Epoch: 2 \t Loss: 0.07806072384119034 \t Accuracy: 70.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 3 \t Loss: 0.08287845966936666 \t Accuracy: 63.2911376953125%\n",
      "Valid Epoch: 3 \t Loss: 0.07766415625810623 \t Accuracy: 70.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 4 \t Loss: 0.08121924121168596 \t Accuracy: 63.2911376953125%\n",
      "Valid Epoch: 4 \t Loss: 0.0772510051727295 \t Accuracy: 70.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 5 \t Loss: 0.08182943301110328 \t Accuracy: 63.2911376953125%\n",
      "Valid Epoch: 5 \t Loss: 0.07751088291406631 \t Accuracy: 70.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 6 \t Loss: 0.08074285335178617 \t Accuracy: 63.924049377441406%\n",
      "Valid Epoch: 6 \t Loss: 0.07831575125455856 \t Accuracy: 70.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 7 \t Loss: 0.07669800086111962 \t Accuracy: 66.45569610595703%\n",
      "Valid Epoch: 7 \t Loss: 0.07837987095117568 \t Accuracy: 70.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 8 \t Loss: 0.07140195822413964 \t Accuracy: 73.417724609375%\n",
      "Valid Epoch: 8 \t Loss: 0.07864000797271728 \t Accuracy: 70.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 9 \t Loss: 0.06516352654257908 \t Accuracy: 76.582275390625%\n",
      "Valid Epoch: 9 \t Loss: 0.08017062842845916 \t Accuracy: 67.5%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 10 \t Loss: 0.05509250507324557 \t Accuracy: 84.17721557617188%\n",
      "Valid Epoch: 10 \t Loss: 0.08159716948866844 \t Accuracy: 65.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 11 \t Loss: 0.045802062636689296 \t Accuracy: 87.97468566894531%\n",
      "Valid Epoch: 11 \t Loss: 0.08527851775288582 \t Accuracy: 62.5%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 12 \t Loss: 0.03846190539719183 \t Accuracy: 91.13924407958984%\n",
      "Valid Epoch: 12 \t Loss: 0.09022303074598312 \t Accuracy: 65.0%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 13 \t Loss: 0.03383196682869634 \t Accuracy: 92.40505981445312%\n",
      "Valid Epoch: 13 \t Loss: 0.09577870890498161 \t Accuracy: 62.5%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 14 \t Loss: 0.0271181316126751 \t Accuracy: 93.67088317871094%\n",
      "Valid Epoch: 14 \t Loss: 0.10542930960655213 \t Accuracy: 57.5%\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 15 \t Loss: 0.022822842614937434 \t Accuracy: 93.67088317871094%\n",
      "Valid Epoch: 15 \t Loss: 0.11210499703884125 \t Accuracy: 55.0%\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10, [1,1,1], 2).to(device)\n",
    "print(model)\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_acc = -1\n",
    "\n",
    "for epoch in range(1, EPOCH+1):\n",
    " \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
    "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
    "        \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
