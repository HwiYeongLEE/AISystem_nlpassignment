{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __라이브러리 로드__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hylee/miniconda3/envs/p3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of comments\n",
    "NOC = 50\n",
    "#k = 0 #start idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1. 데이터 크롤링__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. 데이터 전처리__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __2.1 크롤링 데이터 로드__\n",
    "- 로드 후 일단 10개만 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194914</td>\n",
       "      <td>이 교수님 정말 재미있게 강의해주시네요... 자주 뵈었음 좋겠습니다.</td>\n",
       "      <td>김기범 교수님  쓸데없는 은유나 비유없이  요점만 명확히 설명 해 주셔서  이해도 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     view                                       0  \\\n",
       "0  194914  이 교수님 정말 재미있게 강의해주시네요... 자주 뵈었음 좋겠습니다.   \n",
       "\n",
       "                                                   1  \n",
       "0  김기범 교수님  쓸데없는 은유나 비유없이  요점만 명확히 설명 해 주셔서  이해도 ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"youtube_replies.xlsx\")\n",
    "#cols = list(df.keys())[1:]\n",
    "df_trans = df.T[1:].reset_index()\n",
    "df_trans.rename(columns={'index':'view'}, inplace=True)\n",
    "df_trans.iloc[:1,:3] #example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame([])\n",
    "new_df[\"Views\"] = df_trans[\"view\"]\n",
    "new_df[\"comments\"] = df_trans.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이 교수님 정말 재미있게 강의해주시네요... 자주 뵈었음 좋겠습니다.\\n김기범 교수...</td>\n",
       "      <td>194914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCN에 켠김에 왕까지에서 허준씨를 처음 봤을때는 이렇게 될 줄은 상상도 못 했습니...</td>\n",
       "      <td>319933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교수님 강의를 이렇게 쉽게 들을 수 있다니 행운이고 감사합니다.\\n학창시절땐 과학이...</td>\n",
       "      <td>98384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>영화 &lt;크리에이터&gt; 예매권 이벤트  이 영상에 영화에 대한 기대평 댓글을\\n남겨주신...</td>\n",
       "      <td>402196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>우와 영상 재밌게봤어요! 넘넘 차분하게 전달력 있게 말씀해주시네요.. 하도 슈뢰딩거...</td>\n",
       "      <td>150218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>다양한 천문학 이야기 전할 수 있는 좋은 기회 주신 BODA 분들께 감사드립니다! ...</td>\n",
       "      <td>287723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>곧 안전하고 값싼 우주 여행이 실현되길 바랍니다  우주 여행 관련 이야기할 수 있는...</td>\n",
       "      <td>2298575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>오늘도 초대해 주셔서 감사합니다!!!! 자주 놀러와서 축구 이야기 해볼게요!!영상 ...</td>\n",
       "      <td>362675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>여자를 위해, 여자를 가장 잘 아는 산부인과의사언니 김지연 원장이 개발한 우먼스37...</td>\n",
       "      <td>353262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>스스로 타는 천체, 스타 개그는 제가 만든 거 아닙니다. 저도ㅠ배운거에요.. \\n어...</td>\n",
       "      <td>744042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments    views\n",
       "0    이 교수님 정말 재미있게 강의해주시네요... 자주 뵈었음 좋겠습니다.\\n김기범 교수...   194914\n",
       "1    OCN에 켠김에 왕까지에서 허준씨를 처음 봤을때는 이렇게 될 줄은 상상도 못 했습니...   319933\n",
       "3    교수님 강의를 이렇게 쉽게 들을 수 있다니 행운이고 감사합니다.\\n학창시절땐 과학이...    98384\n",
       "4    영화 <크리에이터> 예매권 이벤트  이 영상에 영화에 대한 기대평 댓글을\\n남겨주신...   402196\n",
       "5    우와 영상 재밌게봤어요! 넘넘 차분하게 전달력 있게 말씀해주시네요.. 하도 슈뢰딩거...   150218\n",
       "..                                                 ...      ...\n",
       "195  다양한 천문학 이야기 전할 수 있는 좋은 기회 주신 BODA 분들께 감사드립니다! ...   287723\n",
       "196  곧 안전하고 값싼 우주 여행이 실현되길 바랍니다  우주 여행 관련 이야기할 수 있는...  2298575\n",
       "197  오늘도 초대해 주셔서 감사합니다!!!! 자주 놀러와서 축구 이야기 해볼게요!!영상 ...   362675\n",
       "198  여자를 위해, 여자를 가장 잘 아는 산부인과의사언니 김지연 원장이 개발한 우먼스37...   353262\n",
       "199  스스로 타는 천체, 스타 개그는 제가 만든 거 아닙니다. 저도ㅠ배운거에요.. \\n어...   744042\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame([])\n",
    "new_df[\"comments\"] = df_trans.iloc[:,1]\n",
    "for i in range(2,NOC+1): \n",
    "    new_df[\"comments\"] += \"\\n\" + df_trans.iloc[:,i]\n",
    "new_df[\"views\"] = df_trans[\"view\"]\n",
    "new_df = new_df.dropna() \n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __2.2 데이터 전처리__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이 교수님 정말 재미있게 강의해주시네요  자주 뵈었음 좋겠습니다  김기범 교수님  ...</td>\n",
       "      <td>194914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCN에 켠김에 왕까지에서 허준씨를 처음 봤을때는 이렇게 될 줄은 상상도 못 했습니...</td>\n",
       "      <td>319933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교수님 강의를 이렇게 쉽게 들을 수 있다니 행운이고 감사합니다  학창시절땐 과학이나...</td>\n",
       "      <td>98384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>영화  크리에이터  예매권 이벤트  이 영상에 영화에 대한 기대평 댓글을 남겨주신 ...</td>\n",
       "      <td>402196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>우와 영상 재밌게봤어요  넘넘 차분하게 전달력 있게 말씀해주시네요  하도 슈뢰딩거고...</td>\n",
       "      <td>150218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>다양한 천문학 이야기 전할 수 있는 좋은 기회 주신 BODA 분들께 감사드립니다  ...</td>\n",
       "      <td>287723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>곧 안전하고 값싼 우주 여행이 실현되길 바랍니다  우주 여행 관련 이야기할 수 있는...</td>\n",
       "      <td>2298575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>오늘도 초대해 주셔서 감사합니다  자주 놀러와서 축구 이야기 해볼게요 영상 재미있게...</td>\n",
       "      <td>362675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>여자를 위해  여자를 가장 잘 아는 산부인과의사언니 김지연 원장이 개발한 우먼스37...</td>\n",
       "      <td>353262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>스스로 타는 천체  스타 개그는 제가 만든 거 아닙니다  저도ㅠ배운거에요   어려울...</td>\n",
       "      <td>744042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments    views\n",
       "0    이 교수님 정말 재미있게 강의해주시네요  자주 뵈었음 좋겠습니다  김기범 교수님  ...   194914\n",
       "1    OCN에 켠김에 왕까지에서 허준씨를 처음 봤을때는 이렇게 될 줄은 상상도 못 했습니...   319933\n",
       "3    교수님 강의를 이렇게 쉽게 들을 수 있다니 행운이고 감사합니다  학창시절땐 과학이나...    98384\n",
       "4    영화  크리에이터  예매권 이벤트  이 영상에 영화에 대한 기대평 댓글을 남겨주신 ...   402196\n",
       "5    우와 영상 재밌게봤어요  넘넘 차분하게 전달력 있게 말씀해주시네요  하도 슈뢰딩거고...   150218\n",
       "..                                                 ...      ...\n",
       "195  다양한 천문학 이야기 전할 수 있는 좋은 기회 주신 BODA 분들께 감사드립니다  ...   287723\n",
       "196  곧 안전하고 값싼 우주 여행이 실현되길 바랍니다  우주 여행 관련 이야기할 수 있는...  2298575\n",
       "197  오늘도 초대해 주셔서 감사합니다  자주 놀러와서 축구 이야기 해볼게요 영상 재미있게...   362675\n",
       "198  여자를 위해  여자를 가장 잘 아는 산부인과의사언니 김지연 원장이 개발한 우먼스37...   353262\n",
       "199  스스로 타는 천체  스타 개그는 제가 만든 거 아닙니다  저도ㅠ배운거에요   어려울...   744042\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#punctuation 제거, 특수문자 제거, lowercasing\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9 a-z A-Z]+', ' ', str(text))\n",
    "    text.lower()\n",
    "    return text\n",
    "\n",
    "new_df.comments = new_df.comments.apply(remove_white_space)\n",
    "new_df.comments = new_df.comments.apply(remove_special_char)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __2.3 토크나이징 및 변수 생성__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','ㅋㅋ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [01:07<00:00,  2.91it/s]\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(new_df['comments']):\n",
    "    tokenized_sentence = okt.morphs(sentence, norm=True, stem=True)  # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[교수, 님, 정말, 재미있다, 강의, 해주다, 자주, 뵈다, 좋다, 김기범, 교수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[OCN, 켜다, 김, 왕, 까지에, 서다, 허준, 씨, 처음, 보다, 때, 이렇게...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[교수, 님, 강의, 이렇게, 쉬다, 들다, 수, 있다, 행운, 이고, 감사하다, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[영화, 크리에이터, 예매, 권, 이벤트, 영상, 영화, 대한, 기, 대, 평, 댓...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[우와, 영상, 재밌다, 보다, 넘다, 넘다, 차분하다, 전달, 력, 있다, 말씀,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[다양하다, 천문학, 이야기, 전, 수, 있다, 좋다, 기회, 주신, BODA, 분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[곧, 안전하다, 값싸다, 우주, 여행, 실현, 되다, 바라다, 우주, 여행, 관련...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[오늘, 초대, 주다, 감사하다, 자주, 놀러와, 서, 축구, 이야기, 해보다, 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[여자, 위해, 여자, 가장, 자다, 알다, 산부인과, 의사, 언니, 김지연, 원장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[스스로, 타다, 천체, 스타, 개그, 제, 만들다, 거, 아니다, 저, ㅠ, 배우...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           token_final\n",
       "0    [교수, 님, 정말, 재미있다, 강의, 해주다, 자주, 뵈다, 좋다, 김기범, 교수...\n",
       "1    [OCN, 켜다, 김, 왕, 까지에, 서다, 허준, 씨, 처음, 보다, 때, 이렇게...\n",
       "2    [교수, 님, 강의, 이렇게, 쉬다, 들다, 수, 있다, 행운, 이고, 감사하다, ...\n",
       "3    [영화, 크리에이터, 예매, 권, 이벤트, 영상, 영화, 대한, 기, 대, 평, 댓...\n",
       "4    [우와, 영상, 재밌다, 보다, 넘다, 넘다, 차분하다, 전달, 력, 있다, 말씀,...\n",
       "..                                                 ...\n",
       "193  [다양하다, 천문학, 이야기, 전, 수, 있다, 좋다, 기회, 주신, BODA, 분...\n",
       "194  [곧, 안전하다, 값싸다, 우주, 여행, 실현, 되다, 바라다, 우주, 여행, 관련...\n",
       "195  [오늘, 초대, 주다, 감사하다, 자주, 놀러와, 서, 축구, 이야기, 해보다, 영...\n",
       "196  [여자, 위해, 여자, 가장, 자다, 알다, 산부인과, 의사, 언니, 김지연, 원장...\n",
       "197  [스스로, 타다, 천체, 스타, 개그, 제, 만들다, 거, 아니다, 저, ㅠ, 배우...\n",
       "\n",
       "[198 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df = pd.DataFrame([])\n",
    "tokenized_df[\"token_final\"] = tokenized_data\n",
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       194914\n",
       "1       319933\n",
       "3        98384\n",
       "4       402196\n",
       "5       150218\n",
       "        ...   \n",
       "195     287723\n",
       "196    2298575\n",
       "197     362675\n",
       "198     353262\n",
       "199     744042\n",
       "Name: views, Length: 198, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[\"views\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[교수, 님, 정말, 재미있다, 강의, 해주다, 자주, 뵈다, 좋다, 김기범, 교수...</td>\n",
       "      <td>194914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[OCN, 켜다, 김, 왕, 까지에, 서다, 허준, 씨, 처음, 보다, 때, 이렇게...</td>\n",
       "      <td>319933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[영화, 크리에이터, 예매, 권, 이벤트, 영상, 영화, 대한, 기, 대, 평, 댓...</td>\n",
       "      <td>98384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[우와, 영상, 재밌다, 보다, 넘다, 넘다, 차분하다, 전달, 력, 있다, 말씀,...</td>\n",
       "      <td>402196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[BODA, X, 우주먼지, 콜라보, 티셔츠, 사르다, https, smartsto...</td>\n",
       "      <td>150218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         token_final   views\n",
       "0  [교수, 님, 정말, 재미있다, 강의, 해주다, 자주, 뵈다, 좋다, 김기범, 교수...  194914\n",
       "1  [OCN, 켜다, 김, 왕, 까지에, 서다, 허준, 씨, 처음, 보다, 때, 이렇게...  319933\n",
       "3  [영화, 크리에이터, 예매, 권, 이벤트, 영상, 영화, 대한, 기, 대, 평, 댓...   98384\n",
       "4  [우와, 영상, 재밌다, 보다, 넘다, 넘다, 차분하다, 전달, 력, 있다, 말씀,...  402196\n",
       "5  [BODA, X, 우주먼지, 콜라보, 티셔츠, 사르다, https, smartsto...  150218"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df = pd.DataFrame([])\n",
    "tokenized_df[\"token_final\"] = tokenized_data\n",
    "tokenized_df[\"views\"] = new_df.views\n",
    "# tokenized_df[\"views\"] = tokenized_df[\"views\"].fillna(tokenized_df['views'].mean()) \n",
    "tokenized_df.dropna(inplace=True)\n",
    "tokenized_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============ 기존 코드 (비교용) ============\n",
    "#df = pd.DataFrame([])\n",
    "#df[\"token_noun\"] = new_df.comments.apply(okt.nouns)\n",
    "#df[\"token_morphs\"] = new_df.comments.apply(okt.morphs)\n",
    "#df[\"label\"] = new_df.label\n",
    "# ============ 저장 ================\n",
    "#df.to_csv(\"origin_noun.csv\", index=False, encoding='utf-8-sig')\n",
    "#df.to_csv(\"origin_morphs.csv\", index=False, encoding='utf-8-sig')\n",
    "tokenized_df.to_csv(\"tokenized_df_reg.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __2.4 단어 임베딩__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=18062, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "embedding_model = Word2Vec(tokenized_df['token_final'], \n",
    "                           sg = 2, # skip-gram\n",
    "                           vector_size = 100, \n",
    "                           window = 2, \n",
    "                           min_count = 1, \n",
    "                           workers = 8\n",
    "                           )\n",
    "\n",
    "print(embedding_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('미생물', 0.9698936343193054), ('방향', 0.9662998914718628), ('음모론', 0.96424800157547), ('길', 0.9633345603942871), ('초전도체', 0.9623009562492371), ('귀신', 0.9619728326797485), ('미래', 0.9615159630775452), ('평생', 0.9613578915596008), ('주변', 0.9612826704978943), ('다만', 0.9611051678657532)]\n"
     ]
    }
   ],
   "source": [
    "embedding_model.wv.save_word2vec_format('week3pj_tokens_eng_w2v_reg')\n",
    "loaded_model = KeyedVectors.load_word2vec_format('week3pj_tokens_eng_w2v_reg') # 모델 로드\n",
    "\n",
    "model_result = loaded_model.most_similar(\"AI\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3. 모델 학습__\n",
    "- 일단 테스트 모델은 임시로 Classification 문제로 정의함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.0 split data - train/val__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['교수', '님', '정말', '재미있다', '강의', '해주다', '자주', '...</td>\n",
       "      <td>194914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['OCN', '켜다', '김', '왕', '까지에', '서다', '허준', '씨'...</td>\n",
       "      <td>319933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['영화', '크리에이터', '예매', '권', '이벤트', '영상', '영화', ...</td>\n",
       "      <td>98384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['우와', '영상', '재밌다', '보다', '넘다', '넘다', '차분하다', ...</td>\n",
       "      <td>402196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['BODA', 'X', '우주먼지', '콜라보', '티셔츠', '사르다', 'ht...</td>\n",
       "      <td>150218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>['다양하다', '천문학', '이야기', '전', '수', '있다', '좋다', '...</td>\n",
       "      <td>132143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>['곧', '안전하다', '값싸다', '우주', '여행', '실현', '되다', '...</td>\n",
       "      <td>758138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>['오늘', '초대', '주다', '감사하다', '자주', '놀러와', '서', '...</td>\n",
       "      <td>287723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>['여자', '위해', '여자', '가장', '자다', '알다', '산부인과', '...</td>\n",
       "      <td>2298575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>['스스로', '타다', '천체', '스타', '개그', '제', '만들다', '거...</td>\n",
       "      <td>362675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           token_final    views\n",
       "0    ['교수', '님', '정말', '재미있다', '강의', '해주다', '자주', '...   194914\n",
       "1    ['OCN', '켜다', '김', '왕', '까지에', '서다', '허준', '씨'...   319933\n",
       "2    ['영화', '크리에이터', '예매', '권', '이벤트', '영상', '영화', ...    98384\n",
       "3    ['우와', '영상', '재밌다', '보다', '넘다', '넘다', '차분하다', ...   402196\n",
       "4    ['BODA', 'X', '우주먼지', '콜라보', '티셔츠', '사르다', 'ht...   150218\n",
       "..                                                 ...      ...\n",
       "191  ['다양하다', '천문학', '이야기', '전', '수', '있다', '좋다', '...   132143\n",
       "192  ['곧', '안전하다', '값싸다', '우주', '여행', '실현', '되다', '...   758138\n",
       "193  ['오늘', '초대', '주다', '감사하다', '자주', '놀러와', '서', '...   287723\n",
       "194  ['여자', '위해', '여자', '가장', '자다', '알다', '산부인과', '...  2298575\n",
       "195  ['스스로', '타다', '천체', '스타', '개그', '제', '만들다', '거...   362675\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tokenized_df_reg.csv\")\n",
    "#df = df.drop(labels=\"Unnamed: 0\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = RandomState()\n",
    "\n",
    "tr = df.sample(frac=0.8, random_state=rng)\n",
    "val = df.loc[~df.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.1 실험 설계__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy.data import Field \n",
    "# from torchtext.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
    "    text = text.split(', ')\n",
    "    return text\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['저', '육군', '2002년', '도에', '제대', '차다', '대단하다', '나라', '지키다', '지키다', '분', '다', '존경', '받다', '초', '급', '것', '중', '급', '것', '중요', '치', '않다', '나라', '위해', '훈련', '받다', '모든', '특수부대', '원', '존경', '하고', '감사하다', '부', '199', '기', '예비역', '음', '탐사', '이며', '근무', '지역', '2', '함대', '전남', '함', '제', '천', '함', '에서', '3년', '5', '개월', '있다', '제', '기수', '전문', '대학', '장학생', '기수', '이며', 'SSU', 'UDT', 'SEAL', 'EOD', '포함', '까지', '있다', '보다', 'UDT', '동기', '을', '감안', '훈련', '조금', '더', '힘들다', '부분', '있다', '저', '기초', '훈련', '끝나다', '후반기', '교육', '을', '기병', '교', '나중', '에는', '정통', '교', '로', '바뀌다', '로', '가다', '많이', '편하다', 'UDT', '동기', '오히려', '후반기', '부터', '본격', '적', '인', '훈련', '시작', '되어다', '후반기', '교육', '받다', '교내', '생활', '때', '밤', '면', '진기', '사', '쪽', '붙다', '특수전', '학교', '에서', '울리다', '비명', '가깝다', '훈련', '고함', '소리', '로', '항상', '듣기', '생식', '주', '훈련', '기본', '이며', '하수', '구', '기다', '훈련', '포박', '잠수', '유영', '훈련', '을', '보다', '정말', '대단하다', '유디티', '훈련', '보', '다니다', '힘들다', '고', '되다', '훈련', '특수전', '요원', '양성', '과정', '이군', '요', '자랑스럽다', '영상', '을', '시청', '응원', '저', '특전', '부사관', '아니다', '초', '급', '반', '까지만', '받다', '중사', '전역', '지만', '모임', '을', '자주', '갖다', '친구', '중', '절반', '특', '전', '부사관', '출신', '이어서', '차다', '재미있다', '보다', '같다', '특전맨', 'UDT', '늘다', '무조건', '인정이', '죠', '인정', '중', '급', '반', '과정', '고통', '극한', '을', '넘어서다', '힘드다', '아니다', '오히려', '즐겁다', '말', '정도', '라는', '게', '진짜', '무섭다', 'ㄷㄷ', '마지막', '퇴', '소전', '자체', '적', '인', '비밀', '작전', '까지', '수행', '정도', '면', 'UDT', '안', '에서도', '수준', '어마', '어마', '차이나다', '방증', 'ㄷㄷ', '8', '47', '명언', '나오다', '평소', '에도', '그만큼', '명예', '로운', '일', '을', '있다', '것', '을', '인지', '하고', '있다', '이다', '군인', '정말', '국가', '보배', '이다', '영재', '학생', '선발', '기준', '과제', '집착', '력', '협동', '심', '아주', '중요하다', '부분', '을', '차지', '하고', '있다', '특수부대', '다른', '분야', '에서의', '영재', '원', '이네', '요', '이렇게', '힘드다', '훈련', '받다', '멋지다', '국가', '위해', '서', '희생', '분', 'UDT', '인데', '최근', '유튜브', '에서', '비추다', 'UDT', '관련', '되다', '분', '모습', '때문', '열심히', '국가', '위해', '서', '지금', '훈련', '보이지', '않다', '곳', '에서', '희생', '분', '차다', '많이', '속상하다', '것', '같다', '이렇다', '분', '대한민국', '특전사', '란', '이름', '지키다', '있다', '때문', '오늘', '난', '영상', '을', '보다', '감사하다', '맘', '하루', '지내다', '감사하다', '고맙다', '김경', '백', '님', '진짜', '투지', '대단하다', '미국', 'buds', '늘다', '진짜', '어떤', '사람', '여야', '그걸', '다', '합격', '외국인', '최초', '이근', '또', '얼마나', '괴물', '이고', '대단하다', '사람', '진짜', 'UDT', '늘다', '진짜', '야', '해군', '복무', '시절', '뭔', '바람', '불다', '진해', '군항', '수리', '함정', '을', '포함', '모든', '함정', '육상', '근무', '까지', '긁다', '모으다', '주둔지', '방어', '훈련', '제대로', '해보다', '실시', '주둔지', '방어', '훈련', '있다', '그때', '특', '전', '여단', '에서', '3', '명', 'UDT', '가다', '침투', '훈련', '시작', '하고', '2', '3시간', '후', '별', '특이', '사항', '없이', '조용하다', '훈련', '끝나다', '아', '물론', 'UDT', '가다', '임무', '끝내다', '빠져나가다', '엔딩', '이다', '직업', '군인', '분들', '에게는', '진짜', '정부', '에서', '지원', '하고', '혜택', '팍팍', '밀다', '야하다', '국가대표', '이기다', '김경', '백', '상사', '님', 'UDT', '저격수', '출신', '최고', '헤어디자이너', '하', '능', '님', '조합', '못', '참다', '김경', '백', '님', '피지', '컬', '인가', '프로그램', '에서', '보다', '근성', '장난', '아니다', '솔', '찍히다', 'udt', '보다', '특전사', '많이', '응원', '김경', '백', '님', '인성', '이나', '근성', '이나', '모든', '면', '에서', '멋지다', '느껴지다', '우선', '인성', '멋지다', '더욱', '멋지다', '든든하다', '멋지다', '응원', 'UDT', '초', '급', '반', '이야기', '많이', '들다', '중', '급', '반', '이야기', '처음', '듣다', '너무', '재미있다', '자다', '들다', '특수부대', '4년', '이상', '만기', '전역', '사람', '에게는', '국가', '에서', '생활', '혜택', '이라는', '제도', '지원', '해주다', '좋다', '전설', '55', '차수', '수석', '이다', '로건', '그', '대체', '이제', '다른', '생각', '을', '되어다', '국군', '훈련', '모든', '것', '제', '생각', '어딘가', '검증', '되다', '훈련', '방법', '을', '도입', '을', '시키다', '것', '이라고', '생각', '하고', '선구자', '서양', '이라고', '생각', '그러므로', '한국', '군', '뛰어나다', '것', '맞다', '뒤', '떨어지다', '생각', '얼마', '전', '진양', '철', '대사', '떠오르다', '어디', '전국체전', '나가다', '방송', '나오다', '그리고', '나오다', '분', '군인', '선구자', '되다', '거', '라고', '믿다', '이근', '2012년', '미국', 'NAVY', 'SEALS', '초', '급', '반', '과정', 'BUD', 'S', '294', '기', '수료', '2012년', '미국', 'NAVY', 'SEALS', '장교', '과정', 'JOTC', '수료', '2013년', '미국', 'NAVY', 'SEALS', '전문화', '과정', 'SQT', '295', '기', '수석', '수료', '네이비실', '초', '급', '반', 'UDT', '초', '급', '중', '급', '고급', '반', '고통', '을', '참고', '이기다', '것', '힘듵', '지만', '짧다', '시간', '을', '극복', '되다', '사회생활', '은근', '끈기', '로', '자존심', '을', '버리다', '길다', '시간', '버티다', '나가야', '되다', '것', '이라서', '군대', '특수', '훈련', '과는', '비교', '안되다', '짱재횽', '동기', '로', '특수부대', '상사', '출신', '답', '게', '언제나', '포기', '모르다', '집념', '사나이', '짜다', '일국', '갱', '백', '횽', '이랑', '최영재', '횽', '이랑', '더불다', '가위', '로', '여성', '분들', '못', '생기다', '자르다', '스타일', '스페샬', '리스트', '하능횽', '이랑', '진짜', '폼', '미치다', '따다', '특전사', '13', '여단', '에서', '물', '고문', '훈련', '받다', '두', '명', '사망', '특부후', '199', '차로', '알다', '정말', '안타깝다', '교육', '훈련', '안전', '보장', '되어다', '초', '급', '반', '백배', '힘들다', '퇴', '교하면', '병과', '바', '끼다', '인제', '군인', '되어다', '집', '생각', '부모님', '생각', '친구', '생각', '여친', '생각', '배고프다', '추다', '앞날', '막막하다', '등등', '중', '급반', '인제', '장기', '직업', '군인', '적응도', '다', '되다', '짬밥', '있다', '무엇', '보다', '밥', '줄이다', 'ㅎ', '차다', '안타깝다', '현실', 'udt', '끼리', '서로', '싸우다', '동료', '안', '버리다', '버리다', '배신', '하고', '차다', '슬프다', '보다', '어디', '던지다', '지도자', '또는', '교육자', '입장', '따르다', '교육', '달라지다', '같다', '어떻다', '분', '사람', '뭐', '든지', '수', '있다', '의지', '만', '있다', '교육', '가능하다', '라고', '일단', '많다', '인원', '을', '이끌다', '가다', '스타일', '이고', '어떻다', '분', '애초', '자격', '미달', '안되다', '되다', '성', '싶다', '나무', '떡잎', '부터', '알아보다', '라면', '서', '매몰', '차다', '커트라인', '에서', '자르다', '버리다', '기도', '개인', '적', '으론', '후자', '표', '주다', '싶다', '오래매달리기', '1등', '하신분아니여', '보고', '경악', '을', 'ㄷㄷ', '멋지다', '성', '님', '월급', '많다', '진짜', '인재', '이여', '우리나라', '특수부대', '특전사', 'hid', 'udt', 'ssu', 'udu', '해', '특수', 'cct', 'sart', '모두', '존경', 'ㅎㅇㅌ', '이번', '강철', '부대', '멤버', '되다', '보여주다', '지나', '번', '피지', '컬때', '너무', '일찍', '탈락', '허다', '많이', '아쉽다', '그대', '진정', '군인', '이며', '애국', '이라', '믿다', '이과', '장님', 'UDT', '폼', '지리다', '버리다', 'ㄷㄷㄷ', '저', '88년', '장교', '로', '임관', '후', '특전사', '에서', '소위', '중령', '까지', '근무', '딱', '보다', '전투력', '엿보다', '이다', '족발', '공수', '작전', '그것', '또한', '작', '전', '수행', '을', '위', '전투력', '이다', '이렇다', '특전사', '분', '전역', '국가', '인재', '로서', '정부', '에서', '자다', '케어', '해주다', '함', '북한', '중국', '이랑', '언제', '전쟁', '터지다', '모르다', '나라', '에서', '군인', '대우', '너무', '후짐', '든든하다', '진짜', '이렇다', '중', '급', '반도', '대단하다', '이근', '미국', '상급', '반', '갓', '근', '초', '급', '반', '버즈', '과정', '이랑은', '차원', '다르다', '이렇다', '고생', '을', '다', '해도', '초임', '하사', '200', '못버', '네', '눈물', '나다', '오다', '슈퍼', '엘리트', '다', '국가', '이런', '분', '전역', '알다', '일', '반', '군인', '보다', '월급', '4', '배', '로', '주다', '1987년', '이라고', '기억', '제', '18', '세', '때', '시내버스', '맨', '뒷', '좌석', '탓', '늘다', '저', '앞', '자리', '군인', '명', '타다', '그', '군인', '당시', '육군', '국방', '색', '군복', '아니다', '조금', '색다르다', '군복', '이다', '해병대', '인가', '공수부대', '나름', '궁금하다', '그', '군인', '군화', '모든', '걸', '이야기', '해주다', '군화', '뒷', '굽이', '바깥쪽', '완전하다', '닿다', '거의', '남다', '않다', '그', '어리다', '얼마나', '훈련', '을', '힘들다', '받다', '고무', '로', '되다', '군화', '뒷', '굽이', '저렇게', '되다', '생각', '되다', '그리고', '그', '군인', '어깨', '매다', '조그마하다', '가방', '황금색', '영어', '로', '언더워터', '데', '몰리', '션', '팀', '이라고', '써다', '있다', '지', '금도', '유디티', '이야기', '나오다', '그', '군인', '군화', '뒷', '굽이', '생각나다', 'ㅎㅎ', '저', '내무부', '소속', '시', '위진', '압', '부대', '전역', '이다', '다감하다', '말씀', '드리다', '유디티', '여러분', '고생', '저', '그', '군화', '오십', '중반', '되다', '지금', '잊다', '없다', '동훈쌤', '폼', '미치다', '벌', '크다', '업', '조권', '폼', '미치다', '황', '쓰다', '봉', '병장', '님', '견디다', '못', '물', '고문', 'ㄷㄷ', '다', '힘드다', '과정', '이고', '어느', '나라', '나', '다', '똑같이', '구분', '초', '급', '반', '중', '급', '반', '고급', '반', '처럼', '직급', '맞다', '교육', '있다', '우선', '특수전', '요원', '근무', '자체', '전문성', '을', '가지다', '전투', '요원', '인데', '초', '급', '반하다', '단기', '로', '4년', '이상', '근무', '하고', '전역', '무시', '수', '없다', '인류', '현대', '식', '무기', '사용', '함', '따르다', '발전', '되다', '들다', '모으다', '편찬', '것', '현재', '전', '술책', '무기', '최신', '화', '되다', '총알', '있다', '포탄', '있다', '전투기', '현재', '스텔스', '까지', '있다', '현재', '전투', '에서', '벌써', '검증', '되다', '작전', '을', '문제', '없다', '것', '을', '기술', '전쟁', '무기', '달라지다', '않다', '크다', '틀다', '조금씩', '보안', '을', '더', '좋아지다', '교범', '대로', '전술', '을', '사용', '4년', '단', '기', '하사', '특수전', '요원', '가장', '멋지다', '생각', '그렇다', '짱', '재', '에이전트', 'H', '덱스', '꼭두각시', '고', '로건', '전', '문', '특수요원', '이다', 'ㄷㄷ', '존잘', '벅', '폼', '미치다', 'ㄷㄷ', '이분', '대단하다', '분', '같다', '정운택', '폼', '미치다', '이렇다', '괴물', '정점', '극악', 'of', '극악', '소문나다', '네이비씰', 'SQT', '교육', '을', '수료', '최초', '이자', '마지막', '외국인', '근', '대위', '있다', '아니다', '그것', '수석', 'ㄷㄷ', '조권', '재희', '폼', '미치다'] 1771967\n",
      "Validation: ['교수', '님', '정말', '재미있다', '강의', '해주다', '자주', '뵈다', '좋다', '김기범', '교수', '님', '쓸데없다', '은유', '나', '비유', '없이', '요점', '만', '명확하다', '설명', '해', '주다', '이해도', '쏙쏙', '되다', '지루하다', '않다', '재밌다', 'ㅉㅉㅉ', '교수', '님', '목소리', '엄청', '좋다', '차분하다', '설명', '을', '엄청', '쉬다', '자다', '같다', '과학', '을', '보다', '함께', '자다', '어울리다', 'ㅎㅎ', '그렇다', '번', '출연', '해주다', '좋다', '더', '더욱', '울릉도', '일', '본', '쪽', '가깝다', '지진', '영향', '울릉도', '아래', '있다', '마그마', '방이', '더', '자극받다', '같다', '전문가', '분', '울릉도', '위험', '1', '순위', '로', '보다', '정부', '차원', '에서도', '울릉도', '주민', '약', '9천', '명', '관광객', '을', '비상', '시', '내륙', '빨리', '대피', '시키다', '있다', '가이드라인', '메뉴얼', '을', '만들다', '않다', '생각', '드네', '요', '공항', '짓다', '어쩌면', 'RuRangE', '돈벌이', '이다', '울릉도', '화', '산이', '폭팔', '진짜', '큰일', '이군', '요', '울릉도', '에서', '폭발', '도망가다', '때', '없다', '그냥', '사람', '전부', '폼페이', '처럼', '녹음', 'ㄷㄷ', '궁금하다', '내용', '재미있다', '보고', '있다', '질문', '있다', '과거', '마그마', '분출', '철원', '평야', '제주도', '지하', '에는', '마그마', '방이', '사라지다', '있다', '어느', '정도', '크기', '로', '재', '분화', '가능성', '있다', '전달', '력', '뛰어나다', '좋다', '영상', '잘봣습니', '다', '멋지다', '꼭', '계속', '활동', '우릴', '지키다', '화산', '대해', '서', '아주', '관심', '갖다', '들다', '더', '크다', '관심', '생기다', '자주', '나오다', '줄다', '역시', '보다', '수준', '최고', '이다', '감사하다', '미래', '울릉도', '화산', '분화', '생각', '못', '재밌다', '들다', '마그마', '분화', '백두산', '후지산', '만', '놓다', '보다', '울릉도', '정말', '생각', '지도', '못', '일', '탈', '계', '팬', '트리', '처자', '여기', '서', 'ㅎ', '몰래', '1', '나잇', '다니다', '긴급', '울릉도', '독도', '사이', '해저화산', '분화', '알다', '울릉도', '더', '분화', '위험', '높다', '일', '탈', '계', '팬', '트리', '처자', '여기', '서', 'ㅎ', '몰래', '1', '나잇', '다니다', '긴급', '마그마', '천천히', '흘러나오다', '독도', '랑', '연결', '되다', '전투기', '뜰', '수', '있다', '미사일', '도배', '수', '있다', '새', '땅', '생깅션', '좋다', '자주', '나오다', '좋다', '말', '톤', '좋다', '화산', '용어', '중', '휴화산', '사화산', '이란', '단어', '더', '이상', '안', '쓰다', '있다', '왜냐하면', '사화산', '인', '줄', '알다', '화산', '활동', '을', '사례', '있다', '일', '탈', '계', '팬', '트리', '처자', '여기', '서', 'ㅎ', '몰래', '1', '나잇', '다니다', '긴급', '기범이', '형', '화이팅', '철원', '위', '추가령', '고대', '화산', '있다', '울릉도', '관광', '영업', '행태', '보다', '서다', '태초', '모습', '리셋', '되다', '것', '나쁘다', '않다', '일', '탈', '계', '팬', '트리', '처자', '여기', '서', 'ㅎ', '몰래', '1', '나잇', '다니다', '긴급', '울릉도', '분화', '가능성', '있다', '아예', '모르다', '경북', '청송', '주왕산', '일반', '그냥', '산', '되다', '게', '천만다행', '이지', '주왕산', '일대', '원래', '화산', '지대', '이다', '울릉도', '뒤통수', '니', '킥', '맞다', '것', '같다', '착각', '들다', '정도', '로', '충격', '적다', '사투리', '한번', '씩', '나오니', '친근하다', '나', '사람', '목소리', '톤', '분위기', '너무', '좋다', '요즘', '이렇다', '텐션', '정도', '딱', '좋다', '것', '같다', '교수', '님', '오리산', '얘기', '해주다', '편안하다', '듣기', '좋다', '목소리', '시', '다', '지질학자', '로', '전향', '무릎', '폼', '미치다', '한반도', '지형', '활화산', '을', '말', '백두산', '한라산', '울릉도', '오리산', '4', '개', '있다', '강', '형', '욱', '님', '언제', '화산', '공부', '까지', '대단하다', '감사하다', '흥미', '롭고', '재밌다', '감사하다', '영상', '에서', '거품', '나', '장소', '어디', '인가요', '다른', '영상', '을', '보다', '수온', '20', '조금', '넘다', '것', '을', '보다', '과학자', '기술자', '전문가', '말', '을', '무시', '안되다', '그', '만큼', '경험', '지식', '있다', '사람', '이라', '100', '수용', '어렵다', '미리', '준비', '그게', '1천년', '후에', '일어나다', '일이', '라', '해도', '설마', '몇', '백년', '후', '에는', '다', '들다', '지', '구', '밖', '정거장', '임시', '머무르다', '다시', '잠잠하다', '지구', '로', '돌아오다', '상황', '있다', '있다', '나리분지', '살다', '분들', '안전', '을', '위해', '서', '주시', '켜다', '아니다', '백두산', '규모', '두다', '뿐', '이다', '조용조', '용', '물', '흐르다', '말', '제', '스탈', '용', '오늘', '한복', '을', '입다', '계시다', '화산', '김구', '선생님', '울릉도', '폭발', '섬', '생기', '면', '개이득', '울릉', '도민', '집값', '떨어지다', '싫어하다', '영상', '1', '위', 'ㅋㅋㅋ', '오다', '진짜', '몰입', '보다', 'ㅎㅎ', '교수', '님', '진짜', '뭔가', '생기다', '고귀하다', '보임', 'ㅋㅋㅋ'] 194914\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy.data import TabularDataset \n",
    "# from torchtext.data import TabularDataset \n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = './',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text,  train[0].label)\n",
    "print(\"Validation:\", validation[0].text, validation[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18062 [00:00<?, ?it/s]Skipping token b'18062' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 18062/18062 [00:00<00:00, 27839.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수와 차원 : torch.Size([16084, 100]) \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.legacy.data import BucketIterator \n",
    "# from torchtext.data import BucketIterator \n",
    "\n",
    "vectors = Vectors(name=\"week3pj_tokens_eng_w2v_reg\")\n",
    "\n",
    "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "# device = \"cpu\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train, validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "\n",
    "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.2 TextCNN 모델링__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class TextCNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
    "    \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()                \n",
    "        self.dropout = nn.Dropout(0.4)         \n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, 1)     \n",
    "        \n",
    "    def forward(self, x):  \n",
    "      \n",
    "        emb_x = self.embed(x)           \n",
    "        emb_x = emb_x.unsqueeze(1)  \n",
    "\n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
    "\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1) \n",
    "        fc_x = fc_x.squeeze(-1)       \n",
    "        fc_x = self.dropout(fc_x)         \n",
    "\n",
    "        logit = self.fc(fc_x)     \n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.3 모델 train/eavluate 함수 정의__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()                               \n",
    "    ae, train_loss = 0.0,0        \n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label      \n",
    "        text = torch.transpose(text, 0, 1)          \n",
    "        target.data.sub_(1)                                 \n",
    "        text, target = text.to(device), target.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()                           \n",
    "        logit = model(text)                         \n",
    "    \n",
    "        loss = F.cross_entropy(logit, target)   \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "        # result = torch.max(logit,1)[1] \n",
    "        ae += torch.sum(torch.abs(logit))\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    mae = ae / len(train_itr.dataset)\n",
    "\n",
    "    return train_loss, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    ae, test_loss = 0.0, 0\n",
    "\n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        \n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "        #print(target,logit)\n",
    "        test_loss += loss.item()\n",
    "        # result = torch.max(logit,1)[1]\n",
    "        ae += torch.sum(torch.abs(logit))\n",
    "\n",
    "    test_loss /= len(itr.dataset) \n",
    "    mae = ae / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __3.4 모델 학습 및 성능 확인__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(16084, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 10, kernel_size=(1, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 10, kernel_size=(1, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 10, kernel_size=(1, 100), stride=(1, 1))\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 14 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m best_test_mae \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCH\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     tr_loss, tr_mae \u001b[39m=\u001b[39m train(model, device, train_iter, optimizer) \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m Loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m MAE: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch, tr_loss, tr_mae))\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     val_loss, val_mae \u001b[39m=\u001b[39m evaluate(model, device, validation_iter)\n",
      "\u001b[1;32m/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()                           \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m logit \u001b[39m=\u001b[39m model(text)                         \n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mcross_entropy(logit, target)   \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()  \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f68796c6565222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6461696e746c616244227d7d/home/hylee/project/AISystem_nlpassignment/Week3/text_preprocessing_Reg.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()  \n",
      "File \u001b[0;32m~/miniconda3/envs/p3/lib/python3.9/site-packages/torch/nn/functional.py:2690\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2688\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2689\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2690\u001b[0m \u001b[39mreturn\u001b[39;00m nll_loss(log_softmax(\u001b[39minput\u001b[39;49m, \u001b[39m1\u001b[39;49m), target, weight, \u001b[39mNone\u001b[39;49;00m, ignore_index, \u001b[39mNone\u001b[39;49;00m, reduction)\n",
      "File \u001b[0;32m~/miniconda3/envs/p3/lib/python3.9/site-packages/torch/nn/functional.py:2385\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2381\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2382\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected input batch_size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) to match target batch_size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), target\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[1;32m   2383\u001b[0m     )\n\u001b[1;32m   2384\u001b[0m \u001b[39mif\u001b[39;00m dim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 2385\u001b[0m     ret \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mnll_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index)\n\u001b[1;32m   2386\u001b[0m \u001b[39melif\u001b[39;00m dim \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m   2387\u001b[0m     ret \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mnll_loss2d(\u001b[39minput\u001b[39m, target, weight, _Reduction\u001b[39m.\u001b[39mget_enum(reduction), ignore_index)\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 14 is out of bounds."
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10, [1,1,1]).to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_mae = -1\n",
    "\n",
    "for epoch in range(1, EPOCH+1):\n",
    " \n",
    "    tr_loss, tr_mae = train(model, device, train_iter, optimizer) \n",
    "    print('Train Epoch: {} \\t Loss: {} \\t MAE: {}%'.format(epoch, tr_loss, tr_mae))\n",
    "    \n",
    "    val_loss, val_mae = evaluate(model, device, validation_iter)\n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t MAE: {}%'.format(epoch, val_loss, val_mae))\n",
    "        \n",
    "    if val_mae > best_test_mae:\n",
    "        best_test_mae = val_mae\n",
    "        \n",
    "        print(\"model saves at {} MAE\".format(best_test_mae))\n",
    "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
